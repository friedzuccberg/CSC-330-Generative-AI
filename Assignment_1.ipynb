{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJGjDlSJK3NEzteVDnlgSa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/friedzuccberg/CSC-330-Generative-AI/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assigment 1 Generative AI 1.26.2026**\n",
        "\n",
        "Description: Practice analyzing how changing the temperature in an LLM influences an LLM's output response"
      ],
      "metadata": {
        "id": "h_Y51DiAyggb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial A"
      ],
      "metadata": {
        "id": "Trqp08r51zvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full loop (generate multiple tokens)\n",
        "# Change steps from 10 to 20 to generate 20 tokens\n",
        "def generate_step_by_step(prompt, steps=20):\n",
        "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    for _ in range(steps):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(tokens)\n",
        "            logits = outputs.logits[:, -1, :]\n",
        "            next_token = sample_next_token(logits, temperature=0.1, top_k=40)\n",
        "\n",
        "        tokens = torch.cat([tokens, next_token], dim=1)\n",
        "        print(tokenizer.decode(tokens[0]))\n",
        "\n",
        "generate_step_by_step(text, steps=20)\n"
      ],
      "metadata": {
        "id": "7Y-vgMelWkKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1357d747-f995-4b98-9453-66c6b2ce3693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My favorite drink is coffee.\n",
            "My favorite drink is coffee. I\n",
            "My favorite drink is coffee. I love\n",
            "My favorite drink is coffee. I love it\n",
            "My favorite drink is coffee. I love it.\n",
            "My favorite drink is coffee. I love it. I\n",
            "My favorite drink is coffee. I love it. I love\n",
            "My favorite drink is coffee. I love it. I love it\n",
            "My favorite drink is coffee. I love it. I love it.\n",
            "My favorite drink is coffee. I love it. I love it. I\n",
            "My favorite drink is coffee. I love it. I love it. I love\n",
            "My favorite drink is coffee. I love it. I love it. I love it\n",
            "My favorite drink is coffee. I love it. I love it. I love it.\n",
            "My favorite drink is coffee. I love it. I love it. I love it. I\n",
            "My favorite drink is coffee. I love it. I love it. I love it. I love\n",
            "My favorite drink is coffee. I love it. I love it. I love it. I love it\n",
            "My favorite drink is coffee. I love it. I love it. I love it. I love it.\n",
            "My favorite drink is coffee. I love it. I love it. I love it. I love it. I\n",
            "My favorite drink is coffee. I love it. I love it. I love it. I love it. I love\n",
            "My favorite drink is coffee. I love it. I love it. I love it. I love it. I love it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial B\n"
      ],
      "metadata": {
        "id": "IrkGYLxX1wFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full loop (generate multiple tokens)\n",
        "# Change steps from 10 to 20 to generate 20 tokens\n",
        "def generate_step_by_step(prompt, steps=20):\n",
        "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    for _ in range(steps):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(tokens)\n",
        "            logits = outputs.logits[:, -1, :]\n",
        "            next_token = sample_next_token(logits, temperature=0.8, top_k=40)\n",
        "\n",
        "        tokens = torch.cat([tokens, next_token], dim=1)\n",
        "        print(tokenizer.decode(tokens[0]))\n",
        "\n",
        "generate_step_by_step(text, steps=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7a9b9f-6367-4d22-906d-faa90a5eb6a5",
        "id": "vROC7imRu7wY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My favorite drink is coffee,\n",
            "My favorite drink is coffee, and\n",
            "My favorite drink is coffee, and I\n",
            "My favorite drink is coffee, and I have\n",
            "My favorite drink is coffee, and I have to\n",
            "My favorite drink is coffee, and I have to admit\n",
            "My favorite drink is coffee, and I have to admit,\n",
            "My favorite drink is coffee, and I have to admit, I\n",
            "My favorite drink is coffee, and I have to admit, I really\n",
            "My favorite drink is coffee, and I have to admit, I really like\n",
            "My favorite drink is coffee, and I have to admit, I really like it\n",
            "My favorite drink is coffee, and I have to admit, I really like it.\n",
            "My favorite drink is coffee, and I have to admit, I really like it. The\n",
            "My favorite drink is coffee, and I have to admit, I really like it. The sweetness\n",
            "My favorite drink is coffee, and I have to admit, I really like it. The sweetness just\n",
            "My favorite drink is coffee, and I have to admit, I really like it. The sweetness just doesn\n",
            "My favorite drink is coffee, and I have to admit, I really like it. The sweetness just doesn't\n",
            "My favorite drink is coffee, and I have to admit, I really like it. The sweetness just doesn't go\n",
            "My favorite drink is coffee, and I have to admit, I really like it. The sweetness just doesn't go away\n",
            "My favorite drink is coffee, and I have to admit, I really like it. The sweetness just doesn't go away,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial C\n"
      ],
      "metadata": {
        "id": "yc3uBSAH1sjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full loop (generate multiple tokens)\n",
        "# Change steps from 10 to 20 to generate 20 tokens\n",
        "def generate_step_by_step(prompt, steps=20):\n",
        "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    for _ in range(steps):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(tokens)\n",
        "            logits = outputs.logits[:, -1, :]\n",
        "            next_token = sample_next_token(logits, temperature=2.0, top_k=40)\n",
        "\n",
        "        tokens = torch.cat([tokens, next_token], dim=1)\n",
        "        print(tokenizer.decode(tokens[0]))\n",
        "\n",
        "generate_step_by_step(text, steps=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c9f3fdb-3032-4c34-d532-07cad2833d00",
        "id": "dHujePHYu5Ma"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My favorite drink is coffee—\n",
            "My favorite drink is coffee—which\n",
            "My favorite drink is coffee—which you\n",
            "My favorite drink is coffee—which you can\n",
            "My favorite drink is coffee—which you can go\n",
            "My favorite drink is coffee—which you can go to\n",
            "My favorite drink is coffee—which you can go to with\n",
            "My favorite drink is coffee—which you can go to with a\n",
            "My favorite drink is coffee—which you can go to with a mix\n",
            "My favorite drink is coffee—which you can go to with a mix-\n",
            "My favorite drink is coffee—which you can go to with a mix-in\n",
            "My favorite drink is coffee—which you can go to with a mix-in,\n",
            "My favorite drink is coffee—which you can go to with a mix-in, the\n",
            "My favorite drink is coffee—which you can go to with a mix-in, the caffeine\n",
            "My favorite drink is coffee—which you can go to with a mix-in, the caffeine makes\n",
            "My favorite drink is coffee—which you can go to with a mix-in, the caffeine makes something\n",
            "My favorite drink is coffee—which you can go to with a mix-in, the caffeine makes something great\n",
            "My favorite drink is coffee—which you can go to with a mix-in, the caffeine makes something great—\n",
            "My favorite drink is coffee—which you can go to with a mix-in, the caffeine makes something great—when\n",
            "My favorite drink is coffee—which you can go to with a mix-in, the caffeine makes something great—when the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt: \"My favorite drink is coffee\"\n",
        "\n",
        "Trial A:\n",
        "\n",
        "  Output: My favorite drink is coffee. I love it. I love it. I love it. I love it. I love it\n",
        "\n",
        "  Rating: 5/10\n",
        "\n",
        "Analysis:\n",
        "  \n",
        "  Trial A used a temperature of .01 when formulating its response to the prompt “ My favorite drink is coffee”. The response repeated the phrase “I love it.” numerous times until it reached the twenty token limit. The reasoning behind this outcome is due to the characteristics of a low temperature. A low temperature in an LLM results in the LLM becoming conservative, choosing the highest probability word every time. The word “favorite” in the prompt is indicative of a likeness for coffee resulting in love being the highest probability word. Due to the fact that this LLM chooses the highest probability word each time, I would use a .01 temperature if I were to build a medical AI to give prescriptions or advice.\n",
        "\n",
        "\n",
        "Trial B:\n",
        "\n",
        "Output: My favorite drink is coffee, and I have to admit, I really like it. The sweetness just doesn't go away,\n",
        "\n",
        "Rating: 7/10\n",
        "\n",
        "\n",
        "Analysis:\n",
        "\n",
        "  Trial B in my opinion was a more plausible result than Trial A even though it had a higher temperature. This is because Trial B did not repeat any words or phrases and went into more detail on why a person might like coffee. The output is written more dream like and I don't think a person would say \"the sweetest doesn't go away\" conversationally. Given these results, I would choose Trial B’s temperature if I were to build an AI to write a surrealist dream-journal.\n",
        "\n",
        "\n",
        "Trial C:\n",
        "\n",
        "Output:My favorite drink is coffee—which you can go to with a mix-in, the caffeine makes something great—when the\n",
        "\n",
        "Rating: 3/10\n",
        "\n",
        "\n",
        "Analysis:\n",
        "\n",
        "  Trial C was the most incoherent out of the trials and this is due to its temperature of 2.0. The response contained words similar/related to coffee such as “caffeine” and “mix-ins”. However the grammatical format of the response made no sense. The context in which the words are used is improper, for example: “can go to with a mix-in” or “the caffeine makes something great” does not translate into a meaningful and plausible response. The increase in temperature/probability distribution, allowed incomprehensible sentences to be formulated because the increase in temperature makes it so every token value is equally as probable.\n"
      ],
      "metadata": {
        "id": "5WRzlzNr1j05"
      }
    }
  ]
}