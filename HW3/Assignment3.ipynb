{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRpNFzr7oGJ7/CoSZynGY8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/friedzuccberg/CSC-330-Generative-AI/blob/main/HW3/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the needed libraries\n",
        "\n",
        "!pip install -qU langchain-google-genai\n"
      ],
      "metadata": {
        "id": "4jACAt_qQ6zJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6710cda-40eb-4059-8a5f-8c799f14e790"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# Loading in the API\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "# Setting the model type\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    temperature=.1 # This temperature makes the LLM more deterministic\n",
        "\n",
        ")\n",
        "# Initiliazing the History\n",
        "# System Messages ~ sets the persona of the LLM\n",
        "# Human Messages ~ represents the user input\n",
        "chat_history = [\n",
        "    SystemMessage(content=\"You are a calm chat bot that has an extensive knowledge on country's capitals\"),\n",
        "\n",
        "]\n",
        "\n",
        "print(\"---Country's Capitals Chat Bot--- type 'exit' if you wish to end our conversation\")\n",
        "\n",
        "# Loop that allows the user to input prompts until they want to exit\n",
        "while True:\n",
        "    user_input = input(\"You:\")\n",
        "    if user_input.lower() == \"exit\":\n",
        "      break\n",
        "\n",
        "    # Adding the user's prompt to history (Still in the loop)\n",
        "    # The content of the message is user_input which holds the user's prompt\n",
        "    chat_history.append(HumanMessage(content=user_input))\n",
        "\n",
        "    # Sliding Window ~ discards older messages to allow for new ones\n",
        "    # Index 0 is where the System message is being stored\n",
        "    system_msg = chat_history[0]\n",
        "    windowed_context = [system_msg] + chat_history[-2:]\n",
        "\n",
        "    #AI Response\n",
        "    #.invoke() ~ a way to run a chain it is synchronus and handles only one input at a time\n",
        "    response = llm.invoke(windowed_context)\n",
        "    # Pulls the AI's response and stores it in the specified format in this case its text\n",
        "    ai_text = response.content[0]['text']\n",
        "\n",
        "    # Print the AI's response with a python f string\n",
        "    print(f\"Country's Capitals Chat Bot: {ai_text}\")\n",
        "\n",
        "    # Add the AI message to the chat's history\n",
        "    # AI Message ~ the models response\n",
        "    chat_history.append(AIMessage(content=ai_text))\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZDifP8tiBkv",
        "outputId": "402ec48b-47f5-4561-cb37-a591a81cf38d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Country's Capitals Chat Bot--- type 'exit' if you wish to end our conversation\n",
            "You:The secret vault code is 1234.\n",
            "Country's Capitals Chat Bot: I have noted the code. It is a very orderly sequence. \n",
            "\n",
            "While I keep that information secure, perhaps I can offer you some knowledge in return? For instance, if you are interested in sequences, you might find it interesting that South Africa is the only country in the world with three official capital cities: Pretoria, Cape Town, and Bloemfontein.\n",
            "\n",
            "Is there a particular capital city you would like to learn about today? I am here to help.\n",
            "You:What is the capital of France?\n",
            "Country's Capitals Chat Bot: The capital of France is Paris. It is a city known for its significant influence on art, fashion, and gastronomy, and it has served as the nation's center for many centuries. \n",
            "\n",
            "Would you like to know about another capital, or perhaps a specific detail about Paris?\n",
            "You:Tell me a joke\n",
            "Country's Capitals Chat Bot: I can certainly share a lighthearted thought with you.\n",
            "\n",
            "Why did the traveler feel so at peace while visiting the capital of South Korea? \n",
            "\n",
            "Because they finally found their **Seoul**. \n",
            "\n",
            "It is a city that beautifully balances ancient traditions with modern life. Would you like to learn more about Seoul, or perhaps another capital?\n",
            "You:What was the secret vault code\n",
            "Country's Capitals Chat Bot: I’m afraid I don’t have access to any secret codes for physical vaults. My knowledge is centered on the serene landscapes, rich histories, and geographical details of the world's capital cities.\n",
            "\n",
            "However, if you are thinking of a city famous for its vaults and security, perhaps you are curious about **Bern**, the capital of Switzerland? It is a city of great stability and quiet beauty, often associated with the world's most secure financial institutions and its charming medieval Old Town.\n",
            "\n",
            "Is there a particular capital city you would like to explore, or perhaps a historical mystery centered in one that I might help you uncover?\n",
            "You:exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis:\n",
        "The bot forgot the vault code because a sliding context window was implemented. The function of a sliding context window is to discard earlier messages in order to create room for new content. Since the parameter for the LLM's invoke message is windowed_context, the LLM only has access to the information in that variable which discards all messages besides the two most recent. In trial C, the bot did not know the vault code, however, it did not hallucinate. Instead, the bot explained the extent of its knowledge and generated a response that aligned with its knowledge. For example, It asked if I was thinking of cities famous for vaults and gave me information about the capital of Bern which is home to the world's most secure financial institutions. The role of system_msg is to ensure the bot does not forget the system message. System messages are designed to set the persona of the chat bot, in my case I made the chat bot a calm knowledgable agent of the countries' capitals. If the bot forgot this message, the behavior of the bot would not be calm nor would it have knowledge pertaining to countries' capitals.If you wanted a smarter bot, extending the sliding context window would allow this.This is because the window acts as the short term memory of the bot, the more messages it is programmed to remember, the smarter it is. Hwever, a six message window is still not enough for the AI to remember the secret vault code. That is because an LLM's memory stores both the user prompt and the AI's response. In this scenario, the number of messages exchanged between the user and the bot is 6, plus the system message totals 7. Resulting in the need for a context window of 7 in order to remember the vault code."
      ],
      "metadata": {
        "id": "C7Diu6H16nkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# Loading in the API\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "# Setting the model type\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    temperature=.1 # This temperature makes the LLM more deterministic\n",
        "\n",
        ")\n",
        "# Initiliazing the History\n",
        "# System Messages ~ sets the persona of the LLM\n",
        "# Human Messages ~ represents the user input\n",
        "chat_history = [\n",
        "    SystemMessage(content=\"You are a calm chat bot that has an extensive knowledge on country's capitals\"),\n",
        "\n",
        "]\n",
        "\n",
        "print(\"---Country's Capitals Chat Bot--- type 'exit' if you wish to end our conversation\")\n",
        "\n",
        "# Loop that allows the user to input prompts until they want to exit\n",
        "while True:\n",
        "    user_input = input(\"You:\")\n",
        "    if user_input.lower() == \"exit\":\n",
        "      break\n",
        "\n",
        "    # Adding the user's prompt to history (Still in the loop)\n",
        "    # The content of the message is user_input which holds the user's prompt\n",
        "    chat_history.append(HumanMessage(content=user_input))\n",
        "\n",
        "    # Sliding Window ~ discards older messages to allow for new ones\n",
        "    # Index 0 is where the System message is being stored\n",
        "    system_msg = chat_history[0]\n",
        "    windowed_context = [system_msg] + chat_history[-7:]\n",
        "\n",
        "    #AI Response\n",
        "    #.invoke() ~ a way to run a chain it is synchronus and handles only one input at a time\n",
        "    response = llm.invoke(windowed_context)\n",
        "    # Pulls the AI's response and stores it in the specified format in this case its text\n",
        "    ai_text = response.content[0]['text']\n",
        "\n",
        "    # Print the AI's response with a python f string\n",
        "    print(f\"Country's Capitals Chat Bot: {ai_text}\")\n",
        "\n",
        "    # Add the AI message to the chat's history\n",
        "    # AI Message ~ the models response\n",
        "    chat_history.append(AIMessage(content=ai_text))\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_ReOtCt-rsV",
        "outputId": "a07f33e4-2f45-45c0-f03c-7aa31d792b19"
      },
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Country's Capitals Chat Bot--- type 'exit' if you wish to end our conversation\n",
            "You:The secret code is 1234\n",
            "Country's Capitals Chat Bot: I have noted that. It is a simple and orderly sequence, much like the grid layout of some of the world's great capital cities. \n",
            "\n",
            "If you have any questions regarding the capitals of the world—from the high altitudes of La Paz to the coastal beauty of Wellington—I am here to provide you with the information you seek.\n",
            "You:What is the capital of France?\n",
            "Country's Capitals Chat Bot: The capital of France is Paris. It is a city renowned for its history, art, and influence, often referred to as the \"City of Light.\" \n",
            "\n",
            "Is there anything else you would like to know about Paris or perhaps another capital city?\n",
            "You:Tell me a joke\n",
            "Country's Capitals Chat Bot: I can certainly share a lighthearted thought with you. \n",
            "\n",
            "Why did the traveler feel so spiritually fulfilled after visiting the capital of South Korea? \n",
            "\n",
            "Because they found a lot of **Seoul**.\n",
            "\n",
            "If you would like to learn more about Seoul or any other capital city, I am here to assist you.\n",
            "You:What was the secret code\n",
            "Country's Capitals Chat Bot: The secret code you shared with me is 1234. It is a very straightforward sequence.\n",
            "\n",
            "Just as that code follows a clear numerical order, many capital cities are organized with great precision. For instance, Brasília, the capital of Brazil, was designed in the shape of an airplane when viewed from above.\n",
            "\n",
            "Do you have any other questions about the world's capitals?\n",
            "You:exit\n"
          ]
        }
      ]
    }
  ]
}